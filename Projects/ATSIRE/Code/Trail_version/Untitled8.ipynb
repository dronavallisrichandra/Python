{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from __future__ import unicode_literals\n",
        "#from gensim.summarization import keywords\n",
        "import pandas as pd\n",
        "import string\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "import pdb\n",
        "import string\n",
        "import matplotlib.pyplot as plt\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "import unicodedata\n",
        "!pip install sumy\n",
        "import re\n",
        "\n",
        "from sumy.parsers.plaintext import PlaintextParser\n",
        "from sumy.nlp.tokenizers import Tokenizer\n",
        "from sumy.summarizers.lex_rank import LexRankSummarizer\n",
        "\n",
        "df =pd.read_csv('./JD_DataScience_USA_small_1.csv', encoding= 'unicode_escape')\n",
        "df1 = pd.read_csv('./Resume_DataScience_Updated.csv', encoding= 'unicode_escape')\n",
        "\n",
        "\n",
        "!pip install wget\n",
        "\n",
        "\n",
        "import wget\n",
        "\n",
        "wget.download(\"https://raw.githubusercontent.com/yogawicaksana/helper_prabowo/main/helper_prabowo_ml.py\",out=\"helper_prabowo_ml.py\")\n",
        "\n",
        "from helper_prabowo_ml import clean_html, remove_links, remove_special_characters, removeStopWords, remove_, remove_digits, lower, email_address, non_ascii, punct\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-jAzij7RH87y",
        "outputId": "5dd4b796-9970-473c-8ee7-e759dc3ceab3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sumy\n",
            "  Downloading sumy-0.11.0-py2.py3-none-any.whl (97 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/97.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.4/97.3 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.3/97.3 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting docopt<0.7,>=0.6.1 (from sumy)\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting breadability>=0.1.20 (from sumy)\n",
            "  Downloading breadability-0.1.20.tar.gz (32 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: requests>=2.7.0 in /usr/local/lib/python3.10/dist-packages (from sumy) (2.27.1)\n",
            "Collecting pycountry>=18.2.23 (from sumy)\n",
            "  Downloading pycountry-22.3.5.tar.gz (10.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m56.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: nltk>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from sumy) (3.8.1)\n",
            "Requirement already satisfied: chardet in /usr/local/lib/python3.10/dist-packages (from breadability>=0.1.20->sumy) (4.0.0)\n",
            "Requirement already satisfied: lxml>=2.0 in /usr/local/lib/python3.10/dist-packages (from breadability>=0.1.20->sumy) (4.9.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk>=3.0.2->sumy) (8.1.4)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>=3.0.2->sumy) (1.3.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>=3.0.2->sumy) (2022.10.31)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk>=3.0.2->sumy) (4.65.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from pycountry>=18.2.23->sumy) (67.7.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.7.0->sumy) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.7.0->sumy) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.7.0->sumy) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.7.0->sumy) (3.4)\n",
            "Building wheels for collected packages: breadability, docopt, pycountry\n",
            "  Building wheel for breadability (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for breadability: filename=breadability-0.1.20-py2.py3-none-any.whl size=21696 sha256=b985e8fd32194c709450625224d4a106ec971f54fd382d30978d16df4dd3ddba\n",
            "  Stored in directory: /root/.cache/pip/wheels/64/22/90/b84fcc30e16598db20a0d41340616dbf9b1e82bbcc627b0b33\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13707 sha256=9c30d5a6d90db699cc678740fcbe45c483148fee5c20ee257aefa1440a7ebd8c\n",
            "  Stored in directory: /root/.cache/pip/wheels/fc/ab/d4/5da2067ac95b36618c629a5f93f809425700506f72c9732fac\n",
            "  Building wheel for pycountry (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycountry: filename=pycountry-22.3.5-py2.py3-none-any.whl size=10681832 sha256=e226558edab28819ef4b5b31ce6eb54593cf931e5ec46d627ae72773ae6a39d1\n",
            "  Stored in directory: /root/.cache/pip/wheels/03/57/cc/290c5252ec97a6d78d36479a3c5e5ecc76318afcb241ad9dbe\n",
            "Successfully built breadability docopt pycountry\n",
            "Installing collected packages: docopt, pycountry, breadability, sumy\n",
            "Successfully installed breadability-0.1.20 docopt-0.6.2 pycountry-22.3.5 sumy-0.11.0\n",
            "Collecting wget\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9657 sha256=d64cacb61057db1f8fa38d7f441dcec11b1b3b3ad78e433612f269e81a277af8\n",
            "  Stored in directory: /root/.cache/pip/wheels/8b/f1/7f/5c94f0a7a505ca1c81cd1d9208ae2064675d97582078e6c769\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Frequency-based methods: These methods use the frequency of words or phrases in the text to identify the most important sentences.\n",
        "#Examples of frequency-based methods include TF-IDF, TextRank, and LexRank.\n"
      ],
      "metadata": {
        "id": "RfuGxf-x3cCL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.dropna()\n",
        "df1 = df1.dropna()"
      ],
      "metadata": {
        "id": "HmQW4hF7IFPq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def text_preprocess(data,col):\n",
        "    data[col] = data[col].apply(func=clean_html)\n",
        "    #data[col] = data[col].apply(func=remove_)\n",
        "    #data[col] = data[col].apply(func=removeStopWords)\n",
        "    #data[col] = data[col].apply(func=remove_digits)\n",
        "    data[col] = data[col].apply(func=remove_links)\n",
        "    data[col] = data[col].apply(func=remove_special_characters)\n",
        "    data[col] = data[col].apply(func=punct)\n",
        "    #data[col] = data[col].apply(func=non_ascii)\n",
        "    data[col] = data[col].apply(func=email_address)\n",
        "    data[col] = data[col].apply(func=lower)\n",
        "    return data\n",
        "\n",
        "\n",
        "#print(resume[0])"
      ],
      "metadata": {
        "id": "mBFZuncyIM3N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = text_preprocess(df,'description')\n",
        "df1 = text_preprocess(df1,'Resume')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b8FLCobeIUe2",
        "outputId": "5835d8de-f106-4afa-d38c-fd59aa0f9998"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-11-be09d5215647>:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data[col] = data[col].apply(func=clean_html)\n",
            "<ipython-input-11-be09d5215647>:6: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data[col] = data[col].apply(func=remove_links)\n",
            "<ipython-input-11-be09d5215647>:7: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data[col] = data[col].apply(func=remove_special_characters)\n",
            "<ipython-input-11-be09d5215647>:8: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data[col] = data[col].apply(func=punct)\n",
            "<ipython-input-11-be09d5215647>:10: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data[col] = data[col].apply(func=email_address)\n",
            "<ipython-input-11-be09d5215647>:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data[col] = data[col].apply(func=lower)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "jd = df['description'].tolist()\n",
        "companies = df['company'].tolist()\n",
        "positions = df['title'].tolist()\n",
        "\n",
        "resume = df1['Resume'].tolist()\n",
        "\n",
        "jd.append(resume[0])"
      ],
      "metadata": {
        "id": "D4LEukAFIZbZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_distances\n",
        "\n",
        "# Define the documents to be transformed\n",
        "documents = [\n",
        "    \"The quick brown fox jumped over the lazy dog.\",\n",
        "    \"Not a blank dog\",\n",
        "    \"The fox\"\n",
        "]\n",
        "\n",
        "# Create a TfidfVectorizer object\n",
        "vectorizer = TfidfVectorizer()\n",
        "\n",
        "# Transform the documents to TF-IDF vectors\n",
        "tfidf_vectors = vectorizer.fit_transform(jd)\n",
        "\n",
        "# Calculate the cosine distance between the first two vectors\n",
        "cosine_distance = cosine_distances(tfidf_vectors[0], tfidf_vectors[1:])\n",
        "\n",
        "# Print the cosine distance\n",
        "print(cosine_distance)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "phagAo7hGJ3P",
        "outputId": "811e82de-910c-4580-f39c-faec0243e533"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.44567027]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "jd1 = df['description'].tolist()\n",
        "companies1 = df['company'].tolist()\n",
        "positions1 = df['title'].tolist()\n",
        "\n",
        "resume1 = df1['Resume'].tolist()\n",
        "\n",
        "jd1.append(resume1[0])"
      ],
      "metadata": {
        "id": "8undSCuyN3fW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sumy.summarizers.text_rank import TextRankSummarizer\n",
        "from sumy.nlp.tokenizers import Tokenizer\n",
        "from sumy.parsers.plaintext import PlaintextParser\n",
        "\n",
        "summarytext = []\n",
        "def textrankfun(textlist):\n",
        "  for text in textlist:\n",
        "        # Create a plaintext parser\n",
        "        parser = PlaintextParser.from_string(text, Tokenizer(\"english\"))\n",
        "\n",
        "        # Create a TextRank summarizer\n",
        "        summarizer = TextRankSummarizer()\n",
        "\n",
        "        # Summarize the document\n",
        "        summary = summarizer(parser.document, sentences_count=1)\n",
        "        summarytext.append(summary[0])\n",
        "\n",
        "  return summarytext\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Pbc351g1JRnW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data1 = textrankfun(jd1)"
      ],
      "metadata": {
        "id": "d-6Vu3J8OQ9z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "str(data1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "id": "kGKH8dMIV4Uo",
        "outputId": "5e175c9d-ab00-4e1f-939e-a06e62c1087d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'[<Sentence: as a data scientist at meta you will shape the future of peoplefacing and businessfacing products we build across our entire family of applications facebook instagram messenger whatsapp oculus by applying your technical skills analytical mindset and product intuition to one of the richest data sets in the world you will help define the experiences we build for billions of people and hundreds of millions of businesses around the world you will collaborate on a wide array of product and business problems with a diverse set of crossfunctional partners across product engineering research data engineering marketing sales finance and others you will use data and analysis to identify and solve product development s biggest challenges you will influence product strategy and investment decisions with data be focused on impact and collaborate with other teams by joining meta you will become part of a worldclass analytics community dedicated to skill development and career growth in analytics and beyond product leadership you will use data to shape product development quantify new opportunities identify upcoming challenges and ensure the products we build bring value to people businesses and meta you will help your partner teams prioritize what to build set goals and understand their product s ecosystem analytics you will guide teams using data and insights you will focus on developing hypotheses and employ a diverse toolkit of rigorous analytical approaches different methodologies frameworks and technical approaches to test them communication and influence you won t simply present data but tell datadriven stories you will convince and influence your partners using clear insights and recommendations you will build credibility through structure and clarity and be a trusted strategic partner data scientist product analytics responsibilities work with large and complex data sets to solve a wide array of challenging problems using different analytical and statistical approaches apply technical expertise with quantitative analysis experimentation data mining and the presentation of data to develop strategies for our products that serve billions of people and hundreds of millions of businesses identify and measure success of product efforts through goal setting forecasting and monitoring of key product metrics to understand trends define understand and test opportunities and levers to improve the product and drive roadmaps through your insights and recommendations partner with product engineering and crossfunctional teams to inform influence support and execute product strategy and investment decisions minimum qualifications bachelor s degree in mathematics statistics a relevant technical field or equivalent practical experience a minimum of 2 years of work experience in analytics minimum of 1 years with a ph d experience with data querying languages e g sql scripting languages e g python and or statistical mathematical software e g rpreferred qualifications masters or ph d degree in a quantitative field meta is proud to be an equal employment opportunity and affirmative action employer we do not discriminate based upon race religion color national origin sex including pregnancy childbirth reproductive health decisions or related medical conditions sexual orientation gender identity gender expression age status as a protected veteran status as an individual with a disability genetic information political views or activity or other applicable legally protected characteristics you may view our equal employment opportunity notice here we also consider qualified applicants with criminal histories consistent with applicable federal state and local law we may use your information to maintain the safety and security of meta its employees and others as required or permitted by law you may view meta s pay transparency policy equal employment opportunity is the law notice and notice to applicants for employment and employees by clicking on their corresponding links additionally meta participates in the everify program in certain locations as required by law>, <Sentence: career summary as a graduate student in data science seeking an internship in tesla as a sales data science internship fall 2023 superb attention to detail highly skilled in python r data wrangling sql data analytics data visualization big data and machine learning with 6 years of experience as a software engineer education university of north texas denton tx expected may 2024 master of science data science gpa 3 85 relevant course work data visualization data analytics data science techniques machine learning data mining prasad v potluri siddhartha institute of technology vijayawada may 2017 bachelor of technology electronics and computer engineering gpa 3 42 skills languages python r sql pl sql powershell micro controller raspberry pi frameworks mvc web api databases mysql bigdata ecosystems hadoop hdfs hbase hive spark kafka data visualizations tableau cloud technologies aws gcp no sql databases cassandra mongodb development methodologies agile scrum waterfall version controls git svm github etl tools ssis reporting tools ms office word excel powerpoint visio outlook ssrs operating systems all versions of unix windows linux automation and ci cd tools jenkins docker git machine learning algorithms linear regression random forest naive bayesian decision tree support vector machine kmean knn neural network deep learning convolutional neural networks cnn artificial neural network ann statistics descriptive statistics probability theory time series analysis bayesian statistics soft skills selfmotivated organized time management independent and flexible project experience iotbased irrigation controller the aim of this work is to develop a smart irrigation monitoring system using raspberry pi the focus area will be parameters such as soil moisture temperature and humidity this system will be a substitute for traditional farming methods comcast telecom consumer complaints analysis used python libraries such as numpy scipy pandas scikitlearn and matplotlib to complete the given analysis and visualization tasks mercedes benz greener manufacturing used python libraries such as numpy pandas scikitlearn seaborn and xg boost to predict the time it takes to pass testing data science capstone healthcare used python libraries such as numpy pandas scikitlearn seaborn matplotlib logistic regression roc curve decision tree classifier random forest support vector classifier and knn to predict if the patients in the dataset have diabetes or not walmart sales prediction implemented a model to predict the sales using numpy pandas scikitlearn seaborn matplotlib regression models to evaluate the performance and accuracy using mse rmse created innovative sheets dashboards and stories to give the insights for the stores data using tableau developed machine models with the perfect fit to predict the future sales multimodal machine learning for detecting and classifying brain tumors using mri scans may 2023present trying to implement the detection and classifying the brain tumours in data centric programming like python and using their libraries such as numpy pandas matplotlib and tensorflow still in the process of data cleaning and research employment experience vertex computer systems dec 2020 jul 2022 hyderabad india role software engineer responsibilities data wrangling to clean transform and reshape the data utilizing python library numpy pandas seaborn scipy matplotlib scikitlearn developed powershell scripts in jams for client api integration for faster data accessing involved in the entire data science project life cycle and actively involved in all the phases including data extraction data cleaning statistical modelling and data visualization with large data sets of structured and unstructured data skilled in advanced regression modelling correlation multivariate analysis model building business intelligence tools and application of statistical concepts automated recurring reports using sql and python and visualized them on bi platforms like tableau updating the stakeholders with the improvements made in automating the tasks managing the workflow and pipeline through airflow used jenkins for data science projects for automating tasks such as data collection preprocessing and model training used docker to create reproducible environments for the data science projects by specifying the exact versions of software packages and libraries for the project so it can run consistently across different computing environments moved 500 manual jobs to jams worked with datasets of varying degrees of size and complexity including both structured and unstructured data optimised the powershell scripts to run less than a 1min implemented sql scripts to extract reports with analytics with exact figures reduced the run threads created for each job from 1000 to less than 100 counts environment python sql powershell ssis jams file zilla sap tableau airflow brandmuscle india pvt ltd apr 2019 dec 2020 bengaluru india role software engineer 2 responsibilities coordinated with the business analyst team to evaluate and improve the performance of the channel builder by query optimization modified existing logic to correct coding errors and handle unhandled exceptions upgrade interfaces and improve overall performance rapidly improved the performance of the checkout flow from 8000ms to 2000ms for a larger amount of orders and integration feasibility into existing systems supervised the support team for various enhancements and bugs and made recommendations to improve order issues by 9 environment web api angular sql mongo db jams camunda file zilla azure blob storage jira devops umbraco kibana brandmuscle india pvt ltd sep 2017 may 2019 bengaluru india role software engineer 1 responsibilities led jams development initiative as subject matter expert and primary pointofcontact for project management staff for implementing the automated sql scripts through jams with a throughput of resources by 50 researched designed and implemented scalable applications for information identification extraction analysis retrieval and indexing has increased the data retrieval speed by 22 major key resource for the migration of windows task scheduler and task scheduler jobs to jams as well as various ssis jobs that are used for clients by using a thirdparty application jams has improved the monitoring developed powershell scripts in jams for client api integration for faster data accessing and injection to database reviewed project specifications and designed technology solutions that met or exceeded client expectations gathered and defined customer requirements to develop clear specifications for creating wellorganized project plans developed and optimized sql stored procedures to load user and location data provided by the client in csv txt format into the database according to client specifications implemented the major enhancement in location builder to trigger the mails using the smtp host environment c net mvc sql powershell ssis jams file zilla azure blob storage jira devops certifications master s program data scientist simplilearn certified in collaboration with ibm aug 2021 data science with python r advance machine learning tableau 10 big data hadoop spark developer data science capstone competitions bike sharing demand prediction competition bike sharing demand nov 2022 i have always been passionate about ml models and entered this competition to have a professional critique of my work i was able to improve my modelling skills and learned more about the use of techniques that improves accuracy i placed third out of 27 teams by a score of 48 41668 regression competition data rush unt s ultimate regression challenge mar 2023present in this competition we are using machine learning models to predict the body fat percentage using regression techniques predicting body fat percentage can be an important part of a person s health profile as it is linked to various health risks such as heart disease diabetes and high blood pressure by accurately predicting body fat percentage healthcare providers can make informed decisions about patients health and provide tailored treatment plans to help manage their health risks student organizations indian student association isa aug 2022 present data science organization jun 2022 present accomplishments star performer award jun 2019 sep 2019 star performer award sep 2019 dec 2019>]'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Iterate over each sentence and replace underscores and spaces\n",
        "for i in range(len(data1)):\n",
        "    data1[i] = str(data1[i]).replace(\"_\", \" \")\n",
        "\n",
        "# Print the updated sentences\n",
        "print(data1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a5X3FUDbVFod",
        "outputId": "a801df17-f2af-46a7-a35a-757fdfc34321"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['as a data scientist at meta you will shape the future of peoplefacing and businessfacing products we build across our entire family of applications facebook instagram messenger whatsapp oculus by applying your technical skills analytical mindset and product intuition to one of the richest data sets in the world you will help define the experiences we build for billions of people and hundreds of millions of businesses around the world you will collaborate on a wide array of product and business problems with a diverse set of crossfunctional partners across product engineering research data engineering marketing sales finance and others you will use data and analysis to identify and solve product development s biggest challenges you will influence product strategy and investment decisions with data be focused on impact and collaborate with other teams by joining meta you will become part of a worldclass analytics community dedicated to skill development and career growth in analytics and beyond product leadership you will use data to shape product development quantify new opportunities identify upcoming challenges and ensure the products we build bring value to people businesses and meta you will help your partner teams prioritize what to build set goals and understand their product s ecosystem analytics you will guide teams using data and insights you will focus on developing hypotheses and employ a diverse toolkit of rigorous analytical approaches different methodologies frameworks and technical approaches to test them communication and influence you won t simply present data but tell datadriven stories you will convince and influence your partners using clear insights and recommendations you will build credibility through structure and clarity and be a trusted strategic partner data scientist product analytics responsibilities work with large and complex data sets to solve a wide array of challenging problems using different analytical and statistical approaches apply technical expertise with quantitative analysis experimentation data mining and the presentation of data to develop strategies for our products that serve billions of people and hundreds of millions of businesses identify and measure success of product efforts through goal setting forecasting and monitoring of key product metrics to understand trends define understand and test opportunities and levers to improve the product and drive roadmaps through your insights and recommendations partner with product engineering and crossfunctional teams to inform influence support and execute product strategy and investment decisions minimum qualifications bachelor s degree in mathematics statistics a relevant technical field or equivalent practical experience a minimum of 2 years of work experience in analytics minimum of 1 years with a ph d experience with data querying languages e g sql scripting languages e g python and or statistical mathematical software e g rpreferred qualifications masters or ph d degree in a quantitative field meta is proud to be an equal employment opportunity and affirmative action employer we do not discriminate based upon race religion color national origin sex including pregnancy childbirth reproductive health decisions or related medical conditions sexual orientation gender identity gender expression age status as a protected veteran status as an individual with a disability genetic information political views or activity or other applicable legally protected characteristics you may view our equal employment opportunity notice here we also consider qualified applicants with criminal histories consistent with applicable federal state and local law we may use your information to maintain the safety and security of meta its employees and others as required or permitted by law you may view meta s pay transparency policy equal employment opportunity is the law notice and notice to applicants for employment and employees by clicking on their corresponding links additionally meta participates in the everify program in certain locations as required by law', 'career summary as a graduate student in data science seeking an internship in tesla as a sales data science internship fall 2023 superb attention to detail highly skilled in python r data wrangling sql data analytics data visualization big data and machine learning with 6 years of experience as a software engineer education university of north texas denton tx expected may 2024 master of science data science gpa 3 85 relevant course work data visualization data analytics data science techniques machine learning data mining prasad v potluri siddhartha institute of technology vijayawada may 2017 bachelor of technology electronics and computer engineering gpa 3 42 skills languages python r sql pl sql powershell micro controller raspberry pi frameworks mvc web api databases mysql bigdata ecosystems hadoop hdfs hbase hive spark kafka data visualizations tableau cloud technologies aws gcp no sql databases cassandra mongodb development methodologies agile scrum waterfall version controls git svm github etl tools ssis reporting tools ms office word excel powerpoint visio outlook ssrs operating systems all versions of unix windows linux automation and ci cd tools jenkins docker git machine learning algorithms linear regression random forest naive bayesian decision tree support vector machine kmean knn neural network deep learning convolutional neural networks cnn artificial neural network ann statistics descriptive statistics probability theory time series analysis bayesian statistics soft skills selfmotivated organized time management independent and flexible project experience iotbased irrigation controller the aim of this work is to develop a smart irrigation monitoring system using raspberry pi the focus area will be parameters such as soil moisture temperature and humidity this system will be a substitute for traditional farming methods comcast telecom consumer complaints analysis used python libraries such as numpy scipy pandas scikitlearn and matplotlib to complete the given analysis and visualization tasks mercedes benz greener manufacturing used python libraries such as numpy pandas scikitlearn seaborn and xg boost to predict the time it takes to pass testing data science capstone healthcare used python libraries such as numpy pandas scikitlearn seaborn matplotlib logistic regression roc curve decision tree classifier random forest support vector classifier and knn to predict if the patients in the dataset have diabetes or not walmart sales prediction implemented a model to predict the sales using numpy pandas scikitlearn seaborn matplotlib regression models to evaluate the performance and accuracy using mse rmse created innovative sheets dashboards and stories to give the insights for the stores data using tableau developed machine models with the perfect fit to predict the future sales multimodal machine learning for detecting and classifying brain tumors using mri scans may 2023present trying to implement the detection and classifying the brain tumours in data centric programming like python and using their libraries such as numpy pandas matplotlib and tensorflow still in the process of data cleaning and research employment experience vertex computer systems dec 2020 jul 2022 hyderabad india role software engineer responsibilities data wrangling to clean transform and reshape the data utilizing python library numpy pandas seaborn scipy matplotlib scikitlearn developed powershell scripts in jams for client api integration for faster data accessing involved in the entire data science project life cycle and actively involved in all the phases including data extraction data cleaning statistical modelling and data visualization with large data sets of structured and unstructured data skilled in advanced regression modelling correlation multivariate analysis model building business intelligence tools and application of statistical concepts automated recurring reports using sql and python and visualized them on bi platforms like tableau updating the stakeholders with the improvements made in automating the tasks managing the workflow and pipeline through airflow used jenkins for data science projects for automating tasks such as data collection preprocessing and model training used docker to create reproducible environments for the data science projects by specifying the exact versions of software packages and libraries for the project so it can run consistently across different computing environments moved 500 manual jobs to jams worked with datasets of varying degrees of size and complexity including both structured and unstructured data optimised the powershell scripts to run less than a 1min implemented sql scripts to extract reports with analytics with exact figures reduced the run threads created for each job from 1000 to less than 100 counts environment python sql powershell ssis jams file zilla sap tableau airflow brandmuscle india pvt ltd apr 2019 dec 2020 bengaluru india role software engineer 2 responsibilities coordinated with the business analyst team to evaluate and improve the performance of the channel builder by query optimization modified existing logic to correct coding errors and handle unhandled exceptions upgrade interfaces and improve overall performance rapidly improved the performance of the checkout flow from 8000ms to 2000ms for a larger amount of orders and integration feasibility into existing systems supervised the support team for various enhancements and bugs and made recommendations to improve order issues by 9 environment web api angular sql mongo db jams camunda file zilla azure blob storage jira devops umbraco kibana brandmuscle india pvt ltd sep 2017 may 2019 bengaluru india role software engineer 1 responsibilities led jams development initiative as subject matter expert and primary pointofcontact for project management staff for implementing the automated sql scripts through jams with a throughput of resources by 50 researched designed and implemented scalable applications for information identification extraction analysis retrieval and indexing has increased the data retrieval speed by 22 major key resource for the migration of windows task scheduler and task scheduler jobs to jams as well as various ssis jobs that are used for clients by using a thirdparty application jams has improved the monitoring developed powershell scripts in jams for client api integration for faster data accessing and injection to database reviewed project specifications and designed technology solutions that met or exceeded client expectations gathered and defined customer requirements to develop clear specifications for creating wellorganized project plans developed and optimized sql stored procedures to load user and location data provided by the client in csv txt format into the database according to client specifications implemented the major enhancement in location builder to trigger the mails using the smtp host environment c net mvc sql powershell ssis jams file zilla azure blob storage jira devops certifications master s program data scientist simplilearn certified in collaboration with ibm aug 2021 data science with python r advance machine learning tableau 10 big data hadoop spark developer data science capstone competitions bike sharing demand prediction competition bike sharing demand nov 2022 i have always been passionate about ml models and entered this competition to have a professional critique of my work i was able to improve my modelling skills and learned more about the use of techniques that improves accuracy i placed third out of 27 teams by a score of 48 41668 regression competition data rush unt s ultimate regression challenge mar 2023present in this competition we are using machine learning models to predict the body fat percentage using regression techniques predicting body fat percentage can be an important part of a person s health profile as it is linked to various health risks such as heart disease diabetes and high blood pressure by accurately predicting body fat percentage healthcare providers can make informed decisions about patients health and provide tailored treatment plans to help manage their health risks student organizations indian student association isa aug 2022 present data science organization jun 2022 present accomplishments star performer award jun 2019 sep 2019 star performer award sep 2019 dec 2019']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(data1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AkplKy2JS3_6",
        "outputId": "c2196415-d352-45dd-8a59-bbc06e05b137"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['as a data scientist at meta you will shape the future of peoplefacing and businessfacing products we build across our entire family of applications facebook instagram messenger whatsapp oculus by applying your technical skills analytical mindset and product intuition to one of the richest data sets in the world you will help define the experiences we build for billions of people and hundreds of millions of businesses around the world you will collaborate on a wide array of product and business problems with a diverse set of crossfunctional partners across product engineering research data engineering marketing sales finance and others you will use data and analysis to identify and solve product development s biggest challenges you will influence product strategy and investment decisions with data be focused on impact and collaborate with other teams by joining meta you will become part of a worldclass analytics community dedicated to skill development and career growth in analytics and beyond product leadership you will use data to shape product development quantify new opportunities identify upcoming challenges and ensure the products we build bring value to people businesses and meta you will help your partner teams prioritize what to build set goals and understand their product s ecosystem analytics you will guide teams using data and insights you will focus on developing hypotheses and employ a diverse toolkit of rigorous analytical approaches different methodologies frameworks and technical approaches to test them communication and influence you won t simply present data but tell datadriven stories you will convince and influence your partners using clear insights and recommendations you will build credibility through structure and clarity and be a trusted strategic partner data scientist product analytics responsibilities work with large and complex data sets to solve a wide array of challenging problems using different analytical and statistical approaches apply technical expertise with quantitative analysis experimentation data mining and the presentation of data to develop strategies for our products that serve billions of people and hundreds of millions of businesses identify and measure success of product efforts through goal setting forecasting and monitoring of key product metrics to understand trends define understand and test opportunities and levers to improve the product and drive roadmaps through your insights and recommendations partner with product engineering and crossfunctional teams to inform influence support and execute product strategy and investment decisions minimum qualifications bachelor s degree in mathematics statistics a relevant technical field or equivalent practical experience a minimum of 2 years of work experience in analytics minimum of 1 years with a ph d experience with data querying languages e g sql scripting languages e g python and or statistical mathematical software e g rpreferred qualifications masters or ph d degree in a quantitative field meta is proud to be an equal employment opportunity and affirmative action employer we do not discriminate based upon race religion color national origin sex including pregnancy childbirth reproductive health decisions or related medical conditions sexual orientation gender identity gender expression age status as a protected veteran status as an individual with a disability genetic information political views or activity or other applicable legally protected characteristics you may view our equal employment opportunity notice here we also consider qualified applicants with criminal histories consistent with applicable federal state and local law we may use your information to maintain the safety and security of meta its employees and others as required or permitted by law you may view meta s pay transparency policy equal employment opportunity is the law notice and notice to applicants for employment and employees by clicking on their corresponding links additionally meta participates in the everify program in certain locations as required by law', 'career summary as a graduate student in data science seeking an internship in tesla as a sales data science internship fall 2023 superb attention to detail highly skilled in python r data wrangling sql data analytics data visualization big data and machine learning with 6 years of experience as a software engineer education university of north texas denton tx expected may 2024 master of science data science gpa 3 85 relevant course work data visualization data analytics data science techniques machine learning data mining prasad v potluri siddhartha institute of technology vijayawada may 2017 bachelor of technology electronics and computer engineering gpa 3 42 skills languages python r sql pl sql powershell micro controller raspberry pi frameworks mvc web api databases mysql bigdata ecosystems hadoop hdfs hbase hive spark kafka data visualizations tableau cloud technologies aws gcp no sql databases cassandra mongodb development methodologies agile scrum waterfall version controls git svm github etl tools ssis reporting tools ms office word excel powerpoint visio outlook ssrs operating systems all versions of unix windows linux automation and ci cd tools jenkins docker git machine learning algorithms linear regression random forest naive bayesian decision tree support vector machine kmean knn neural network deep learning convolutional neural networks cnn artificial neural network ann statistics descriptive statistics probability theory time series analysis bayesian statistics soft skills selfmotivated organized time management independent and flexible project experience iotbased irrigation controller the aim of this work is to develop a smart irrigation monitoring system using raspberry pi the focus area will be parameters such as soil moisture temperature and humidity this system will be a substitute for traditional farming methods comcast telecom consumer complaints analysis used python libraries such as numpy scipy pandas scikitlearn and matplotlib to complete the given analysis and visualization tasks mercedes benz greener manufacturing used python libraries such as numpy pandas scikitlearn seaborn and xg boost to predict the time it takes to pass testing data science capstone healthcare used python libraries such as numpy pandas scikitlearn seaborn matplotlib logistic regression roc curve decision tree classifier random forest support vector classifier and knn to predict if the patients in the dataset have diabetes or not walmart sales prediction implemented a model to predict the sales using numpy pandas scikitlearn seaborn matplotlib regression models to evaluate the performance and accuracy using mse rmse created innovative sheets dashboards and stories to give the insights for the stores data using tableau developed machine models with the perfect fit to predict the future sales multimodal machine learning for detecting and classifying brain tumors using mri scans may 2023present trying to implement the detection and classifying the brain tumours in data centric programming like python and using their libraries such as numpy pandas matplotlib and tensorflow still in the process of data cleaning and research employment experience vertex computer systems dec 2020 jul 2022 hyderabad india role software engineer responsibilities data wrangling to clean transform and reshape the data utilizing python library numpy pandas seaborn scipy matplotlib scikitlearn developed powershell scripts in jams for client api integration for faster data accessing involved in the entire data science project life cycle and actively involved in all the phases including data extraction data cleaning statistical modelling and data visualization with large data sets of structured and unstructured data skilled in advanced regression modelling correlation multivariate analysis model building business intelligence tools and application of statistical concepts automated recurring reports using sql and python and visualized them on bi platforms like tableau updating the stakeholders with the improvements made in automating the tasks managing the workflow and pipeline through airflow used jenkins for data science projects for automating tasks such as data collection preprocessing and model training used docker to create reproducible environments for the data science projects by specifying the exact versions of software packages and libraries for the project so it can run consistently across different computing environments moved 500 manual jobs to jams worked with datasets of varying degrees of size and complexity including both structured and unstructured data optimised the powershell scripts to run less than a 1min implemented sql scripts to extract reports with analytics with exact figures reduced the run threads created for each job from 1000 to less than 100 counts environment python sql powershell ssis jams file zilla sap tableau airflow brandmuscle india pvt ltd apr 2019 dec 2020 bengaluru india role software engineer 2 responsibilities coordinated with the business analyst team to evaluate and improve the performance of the channel builder by query optimization modified existing logic to correct coding errors and handle unhandled exceptions upgrade interfaces and improve overall performance rapidly improved the performance of the checkout flow from 8000ms to 2000ms for a larger amount of orders and integration feasibility into existing systems supervised the support team for various enhancements and bugs and made recommendations to improve order issues by 9 environment web api angular sql mongo db jams camunda file zilla azure blob storage jira devops umbraco kibana brandmuscle india pvt ltd sep 2017 may 2019 bengaluru india role software engineer 1 responsibilities led jams development initiative as subject matter expert and primary pointofcontact for project management staff for implementing the automated sql scripts through jams with a throughput of resources by 50 researched designed and implemented scalable applications for information identification extraction analysis retrieval and indexing has increased the data retrieval speed by 22 major key resource for the migration of windows task scheduler and task scheduler jobs to jams as well as various ssis jobs that are used for clients by using a thirdparty application jams has improved the monitoring developed powershell scripts in jams for client api integration for faster data accessing and injection to database reviewed project specifications and designed technology solutions that met or exceeded client expectations gathered and defined customer requirements to develop clear specifications for creating wellorganized project plans developed and optimized sql stored procedures to load user and location data provided by the client in csv txt format into the database according to client specifications implemented the major enhancement in location builder to trigger the mails using the smtp host environment c net mvc sql powershell ssis jams file zilla azure blob storage jira devops certifications master s program data scientist simplilearn certified in collaboration with ibm aug 2021 data science with python r advance machine learning tableau 10 big data hadoop spark developer data science capstone competitions bike sharing demand prediction competition bike sharing demand nov 2022 i have always been passionate about ml models and entered this competition to have a professional critique of my work i was able to improve my modelling skills and learned more about the use of techniques that improves accuracy i placed third out of 27 teams by a score of 48 41668 regression competition data rush unt s ultimate regression challenge mar 2023present in this competition we are using machine learning models to predict the body fat percentage using regression techniques predicting body fat percentage can be an important part of a person s health profile as it is linked to various health risks such as heart disease diabetes and high blood pressure by accurately predicting body fat percentage healthcare providers can make informed decisions about patients health and provide tailored treatment plans to help manage their health risks student organizations indian student association isa aug 2022 present data science organization jun 2022 present accomplishments star performer award jun 2019 sep 2019 star performer award sep 2019 dec 2019']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_distances\n",
        "\n",
        "\n",
        "# Create a TfidfVectorizer object\n",
        "vectorizer = TfidfVectorizer()\n",
        "\n",
        "# Transform the documents to TF-IDF vectors\n",
        "tfidf_vectors = vectorizer.fit_transform(data1)\n",
        "\n",
        "# Calculate the cosine distance between the first two vectors\n",
        "cosine_distance = cosine_distances(tfidf_vectors[0], tfidf_vectors[1:])\n",
        "\n",
        "# Print the cosine distance\n",
        "print(cosine_distance)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uzs44rwDSjN1",
        "outputId": "76c3344f-d3c3-4872-c5f3-a985d1a8f265"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.44567027]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "jd2 = df['description'].tolist()\n",
        "companies2 = df['company'].tolist()\n",
        "positions2 = df['title'].tolist()\n",
        "\n",
        "resume2 = df1['Resume'].tolist()\n",
        "\n",
        "jd2.append(resume2[0])"
      ],
      "metadata": {
        "id": "nqhCDHnC1SfJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sumy.summarizers.lex_rank import LexRankSummarizer\n",
        "from sumy.nlp.tokenizers import Tokenizer\n",
        "from sumy.parsers.plaintext import PlaintextParser\n",
        "\n",
        "summarytext = []\n",
        "def textrankfun(textlist):\n",
        "  for text in textlist:\n",
        "        # Create a plaintext parser\n",
        "        parser = PlaintextParser.from_string(text, Tokenizer(\"english\"))\n",
        "\n",
        "        # Create a TextRank summarizer\n",
        "        summarizer = LexRankSummarizer()\n",
        "\n",
        "        # Summarize the document\n",
        "        summary = summarizer(parser.document, sentences_count=1)\n",
        "        summarytext.append(summary[0])\n",
        "\n",
        "  return summarytext"
      ],
      "metadata": {
        "id": "L-JoQQpk17pL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data2 = textrankfun(jd2)"
      ],
      "metadata": {
        "id": "ORRanwpu17sY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Iterate over each sentence and replace underscores and spaces\n",
        "for i in range(len(data2)):\n",
        "    data2[i] = str(data2[i]).replace(\"_\", \" \")\n",
        "\n",
        "# Print the updated sentences\n",
        "print(data2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SVjOy3ov17v9",
        "outputId": "4a84dcbe-47a5-4e50-8597-9e678dd3d43c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['as a data scientist at meta you will shape the future of peoplefacing and businessfacing products we build across our entire family of applications facebook instagram messenger whatsapp oculus by applying your technical skills analytical mindset and product intuition to one of the richest data sets in the world you will help define the experiences we build for billions of people and hundreds of millions of businesses around the world you will collaborate on a wide array of product and business problems with a diverse set of crossfunctional partners across product engineering research data engineering marketing sales finance and others you will use data and analysis to identify and solve product development s biggest challenges you will influence product strategy and investment decisions with data be focused on impact and collaborate with other teams by joining meta you will become part of a worldclass analytics community dedicated to skill development and career growth in analytics and beyond product leadership you will use data to shape product development quantify new opportunities identify upcoming challenges and ensure the products we build bring value to people businesses and meta you will help your partner teams prioritize what to build set goals and understand their product s ecosystem analytics you will guide teams using data and insights you will focus on developing hypotheses and employ a diverse toolkit of rigorous analytical approaches different methodologies frameworks and technical approaches to test them communication and influence you won t simply present data but tell datadriven stories you will convince and influence your partners using clear insights and recommendations you will build credibility through structure and clarity and be a trusted strategic partner data scientist product analytics responsibilities work with large and complex data sets to solve a wide array of challenging problems using different analytical and statistical approaches apply technical expertise with quantitative analysis experimentation data mining and the presentation of data to develop strategies for our products that serve billions of people and hundreds of millions of businesses identify and measure success of product efforts through goal setting forecasting and monitoring of key product metrics to understand trends define understand and test opportunities and levers to improve the product and drive roadmaps through your insights and recommendations partner with product engineering and crossfunctional teams to inform influence support and execute product strategy and investment decisions minimum qualifications bachelor s degree in mathematics statistics a relevant technical field or equivalent practical experience a minimum of 2 years of work experience in analytics minimum of 1 years with a ph d experience with data querying languages e g sql scripting languages e g python and or statistical mathematical software e g rpreferred qualifications masters or ph d degree in a quantitative field meta is proud to be an equal employment opportunity and affirmative action employer we do not discriminate based upon race religion color national origin sex including pregnancy childbirth reproductive health decisions or related medical conditions sexual orientation gender identity gender expression age status as a protected veteran status as an individual with a disability genetic information political views or activity or other applicable legally protected characteristics you may view our equal employment opportunity notice here we also consider qualified applicants with criminal histories consistent with applicable federal state and local law we may use your information to maintain the safety and security of meta its employees and others as required or permitted by law you may view meta s pay transparency policy equal employment opportunity is the law notice and notice to applicants for employment and employees by clicking on their corresponding links additionally meta participates in the everify program in certain locations as required by law', 'career summary as a graduate student in data science seeking an internship in tesla as a sales data science internship fall 2023 superb attention to detail highly skilled in python r data wrangling sql data analytics data visualization big data and machine learning with 6 years of experience as a software engineer education university of north texas denton tx expected may 2024 master of science data science gpa 3 85 relevant course work data visualization data analytics data science techniques machine learning data mining prasad v potluri siddhartha institute of technology vijayawada may 2017 bachelor of technology electronics and computer engineering gpa 3 42 skills languages python r sql pl sql powershell micro controller raspberry pi frameworks mvc web api databases mysql bigdata ecosystems hadoop hdfs hbase hive spark kafka data visualizations tableau cloud technologies aws gcp no sql databases cassandra mongodb development methodologies agile scrum waterfall version controls git svm github etl tools ssis reporting tools ms office word excel powerpoint visio outlook ssrs operating systems all versions of unix windows linux automation and ci cd tools jenkins docker git machine learning algorithms linear regression random forest naive bayesian decision tree support vector machine kmean knn neural network deep learning convolutional neural networks cnn artificial neural network ann statistics descriptive statistics probability theory time series analysis bayesian statistics soft skills selfmotivated organized time management independent and flexible project experience iotbased irrigation controller the aim of this work is to develop a smart irrigation monitoring system using raspberry pi the focus area will be parameters such as soil moisture temperature and humidity this system will be a substitute for traditional farming methods comcast telecom consumer complaints analysis used python libraries such as numpy scipy pandas scikitlearn and matplotlib to complete the given analysis and visualization tasks mercedes benz greener manufacturing used python libraries such as numpy pandas scikitlearn seaborn and xg boost to predict the time it takes to pass testing data science capstone healthcare used python libraries such as numpy pandas scikitlearn seaborn matplotlib logistic regression roc curve decision tree classifier random forest support vector classifier and knn to predict if the patients in the dataset have diabetes or not walmart sales prediction implemented a model to predict the sales using numpy pandas scikitlearn seaborn matplotlib regression models to evaluate the performance and accuracy using mse rmse created innovative sheets dashboards and stories to give the insights for the stores data using tableau developed machine models with the perfect fit to predict the future sales multimodal machine learning for detecting and classifying brain tumors using mri scans may 2023present trying to implement the detection and classifying the brain tumours in data centric programming like python and using their libraries such as numpy pandas matplotlib and tensorflow still in the process of data cleaning and research employment experience vertex computer systems dec 2020 jul 2022 hyderabad india role software engineer responsibilities data wrangling to clean transform and reshape the data utilizing python library numpy pandas seaborn scipy matplotlib scikitlearn developed powershell scripts in jams for client api integration for faster data accessing involved in the entire data science project life cycle and actively involved in all the phases including data extraction data cleaning statistical modelling and data visualization with large data sets of structured and unstructured data skilled in advanced regression modelling correlation multivariate analysis model building business intelligence tools and application of statistical concepts automated recurring reports using sql and python and visualized them on bi platforms like tableau updating the stakeholders with the improvements made in automating the tasks managing the workflow and pipeline through airflow used jenkins for data science projects for automating tasks such as data collection preprocessing and model training used docker to create reproducible environments for the data science projects by specifying the exact versions of software packages and libraries for the project so it can run consistently across different computing environments moved 500 manual jobs to jams worked with datasets of varying degrees of size and complexity including both structured and unstructured data optimised the powershell scripts to run less than a 1min implemented sql scripts to extract reports with analytics with exact figures reduced the run threads created for each job from 1000 to less than 100 counts environment python sql powershell ssis jams file zilla sap tableau airflow brandmuscle india pvt ltd apr 2019 dec 2020 bengaluru india role software engineer 2 responsibilities coordinated with the business analyst team to evaluate and improve the performance of the channel builder by query optimization modified existing logic to correct coding errors and handle unhandled exceptions upgrade interfaces and improve overall performance rapidly improved the performance of the checkout flow from 8000ms to 2000ms for a larger amount of orders and integration feasibility into existing systems supervised the support team for various enhancements and bugs and made recommendations to improve order issues by 9 environment web api angular sql mongo db jams camunda file zilla azure blob storage jira devops umbraco kibana brandmuscle india pvt ltd sep 2017 may 2019 bengaluru india role software engineer 1 responsibilities led jams development initiative as subject matter expert and primary pointofcontact for project management staff for implementing the automated sql scripts through jams with a throughput of resources by 50 researched designed and implemented scalable applications for information identification extraction analysis retrieval and indexing has increased the data retrieval speed by 22 major key resource for the migration of windows task scheduler and task scheduler jobs to jams as well as various ssis jobs that are used for clients by using a thirdparty application jams has improved the monitoring developed powershell scripts in jams for client api integration for faster data accessing and injection to database reviewed project specifications and designed technology solutions that met or exceeded client expectations gathered and defined customer requirements to develop clear specifications for creating wellorganized project plans developed and optimized sql stored procedures to load user and location data provided by the client in csv txt format into the database according to client specifications implemented the major enhancement in location builder to trigger the mails using the smtp host environment c net mvc sql powershell ssis jams file zilla azure blob storage jira devops certifications master s program data scientist simplilearn certified in collaboration with ibm aug 2021 data science with python r advance machine learning tableau 10 big data hadoop spark developer data science capstone competitions bike sharing demand prediction competition bike sharing demand nov 2022 i have always been passionate about ml models and entered this competition to have a professional critique of my work i was able to improve my modelling skills and learned more about the use of techniques that improves accuracy i placed third out of 27 teams by a score of 48 41668 regression competition data rush unt s ultimate regression challenge mar 2023present in this competition we are using machine learning models to predict the body fat percentage using regression techniques predicting body fat percentage can be an important part of a person s health profile as it is linked to various health risks such as heart disease diabetes and high blood pressure by accurately predicting body fat percentage healthcare providers can make informed decisions about patients health and provide tailored treatment plans to help manage their health risks student organizations indian student association isa aug 2022 present data science organization jun 2022 present accomplishments star performer award jun 2019 sep 2019 star performer award sep 2019 dec 2019']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_distances\n",
        "\n",
        "\n",
        "# Create a TfidfVectorizer object\n",
        "vectorizer = TfidfVectorizer()\n",
        "\n",
        "# Transform the documents to TF-IDF vectors\n",
        "tfidf_vectors = vectorizer.fit_transform(data2)\n",
        "\n",
        "# Calculate the cosine distance between the first two vectors\n",
        "cosine_distance = cosine_distances(tfidf_vectors[0], tfidf_vectors[1:])\n",
        "\n",
        "# Print the cosine distance\n",
        "print(cosine_distance)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X4RlHSAA2iRG",
        "outputId": "f66c7585-598b-424a-db56-0b3742ea54bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.44567027]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "###############################################################"
      ],
      "metadata": {
        "id": "-CZ2ZucJ1718"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oHzAWfbWTftM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}